{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d44c40d",
   "metadata": {},
   "source": [
    "# SpotFake: Twitter Fake News Detection - Kaggle TPU v5e-8 Edition\n",
    "\n",
    "This notebook is optimized for Kaggle with TPU v5e-8 support.\n",
    "\n",
    "**Important Setup Steps:**\n",
    "1. In Kaggle Settings: Select **TPU v5e-8** as accelerator\n",
    "2. Add your dataset to Kaggle Datasets\n",
    "3. Run all cells in order\n",
    "\n",
    "This notebook provides:\n",
    "1. Loading and preprocessing data (text + images)\n",
    "2. Building the multimodal model (BERT + VGG19)\n",
    "3. Training the model with TPU acceleration\n",
    "4. Making predictions on new inputs (text + image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17caa79b",
   "metadata": {},
   "source": [
    "## 1. TPU Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40271f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import gc\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPU Detection and Initialization\n",
    "def setup_tpu():\n",
    "    \"\"\"Configure TPU if available, otherwise use GPU/CPU\"\"\"\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(\"✓ TPU initialized successfully!\")\n",
    "        print(f\"  TPU devices: {tpu.cluster_spec().as_dict()['worker']}\")\n",
    "        print(f\"  Number of replicas: {strategy.num_replicas_in_sync}\")\n",
    "        return strategy, True\n",
    "    except ValueError:\n",
    "        print(\"⚠ TPU not found. Using default strategy (GPU/CPU)\")\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        return strategy, False\n",
    "\n",
    "strategy, using_tpu = setup_tpu()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Suppress TF warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(f\"\\nRunning on: {'TPU' if using_tpu else 'GPU/CPU'}\")\n",
    "print(f\"Number of accelerators: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 23\n",
    "img_length = 224\n",
    "img_width = 224\n",
    "img_channels = 3\n",
    "\n",
    "# Kaggle paths - adjust these based on your dataset location\n",
    "# If you uploaded the dataset to Kaggle, it will be in /kaggle/input/\n",
    "DATASET_PATH = '/kaggle/input/spotfake-twitter'  # Change this to your dataset name\n",
    "# For testing locally, uncomment:\n",
    "# DATASET_PATH = 'dataset/twitter'\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66aca1c",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c77af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress callback\n",
    "def live():\n",
    "    \"\"\"Simple callback for training progress\"\"\"\n",
    "    return tf.keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch, logs: print(\n",
    "            f\"Epoch {epoch + 1}: loss={logs.get('loss', 0):.4f}, \"\n",
    "            f\"acc={logs.get('accuracy', 0):.4f}, \"\n",
    "            f\"val_loss={logs.get('val_loss', 0):.4f}, \"\n",
    "            f\"val_acc={logs.get('val_accuracy', 0):.4f}\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd327d",
   "metadata": {},
   "source": [
    "### Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717516bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example for padding.\"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the BERT tokenizer.\"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    return tokenizer\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single InputExample into features.\"\"\"\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        example.text_a,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_seq_length,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'][0].numpy().tolist()\n",
    "    input_mask = encoding['attention_mask'][0].numpy().tolist()\n",
    "    segment_ids = [0] * max_seq_length\n",
    "    \n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of InputExamples to features.\"\"\"\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples from texts and labels.\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=text if isinstance(text, str) else \" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "\n",
    "def preprocess_text_input(text, tokenizer, max_seq_length=23):\n",
    "    \"\"\"Preprocess a single text input for prediction.\"\"\"\n",
    "    example = InputExample(guid=None, text_a=text, text_b=None, label=0)\n",
    "    input_id, input_mask, segment_id, _ = convert_single_example(\n",
    "        tokenizer, example, max_seq_length\n",
    "    )\n",
    "    return np.array([input_id]), np.array([input_mask]), np.array([segment_id])\n",
    "\n",
    "print(\"✓ Text preprocessing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5aed17",
   "metadata": {},
   "source": [
    "### Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ea8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_image(list_of_images, length=224, width=224):\n",
    "    \"\"\"Read and preprocess multiple images.\"\"\"\n",
    "    X = [] \n",
    "    for image in tqdm(list_of_images, desc=\"Processing images\"):\n",
    "        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (length, width), interpolation=cv2.INTER_CUBIC))  \n",
    "    return np.array(X)\n",
    "\n",
    "def preprocess_single_image(image_path, length=224, width=224):\n",
    "    \"\"\"Preprocess a single image for prediction.\"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image from {image_path}\")\n",
    "    img = cv2.resize(img, (length, width), interpolation=cv2.INTER_CUBIC)\n",
    "    # Convert to (channels, height, width) format\n",
    "    img = np.rollaxis(img, 2, 0)\n",
    "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "print(\"✓ Image preprocessing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccff980",
   "metadata": {},
   "source": [
    "## 3. Model Definition (TPU-Compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_model(params):\n",
    "    \"\"\"Build the multimodal fake news detection model - TPU compatible.\"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # BERT encoder function\n",
    "    def bert_encode(input_ids, input_mask, segment_ids):\n",
    "        bert_layer = hub.KerasLayer(\n",
    "            bert_path,\n",
    "            trainable=False,\n",
    "            signature=\"tokens\",\n",
    "            signature_outputs_as_dict=True,\n",
    "        )\n",
    "        bert_inputs = {\n",
    "            \"input_ids\": input_ids, \n",
    "            \"input_mask\": input_mask, \n",
    "            \"segment_ids\": segment_ids\n",
    "        }\n",
    "        bert_outputs = bert_layer(bert_inputs)\n",
    "        return bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    # Text input branch\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\", dtype=tf.int32)\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\", dtype=tf.int32)\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\", dtype=tf.int32)\n",
    "    \n",
    "    bert_output = tf.keras.layers.Lambda(\n",
    "        lambda inputs: bert_encode(inputs[0], inputs[1], inputs[2]),\n",
    "        output_shape=(768,),\n",
    "        name=\"bert_encoding\"\n",
    "    )([in_id, in_mask, in_segment])\n",
    "\n",
    "    if params['text_no_hidden_layer'] > 0:\n",
    "        for i in range(params['text_no_hidden_layer']):\n",
    "            bert_output = tf.keras.layers.Dense(params['text_hidden_neurons'], activation='relu')(bert_output)\n",
    "            bert_output = tf.keras.layers.Dropout(params['dropout'])(bert_output)\n",
    "\n",
    "    text_repr = tf.keras.layers.Dense(params['repr_size'], activation='relu')(bert_output)\n",
    "\n",
    "    # Image input branch (VGG19)\n",
    "    conv_base = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_image = tf.keras.layers.Input(shape=(3, 224, 224))\n",
    "    transposed_image = tf.keras.layers.Lambda(lambda x: tf.transpose(x, [0, 2, 3, 1]))(input_image)\n",
    "    base_output = conv_base(transposed_image)\n",
    "    flat = tf.keras.layers.Flatten()(base_output)\n",
    "\n",
    "    if params['vis_no_hidden_layer'] > 0:\n",
    "        for i in range(params['vis_no_hidden_layer']):\n",
    "            flat = tf.keras.layers.Dense(params['vis_hidden_neurons'], activation='relu')(flat)\n",
    "            flat = tf.keras.layers.Dropout(params['dropout'])(flat)\n",
    "\n",
    "    visual_repr = tf.keras.layers.Dense(params['repr_size'], activation='relu')(flat)\n",
    "\n",
    "    # Classifier (combine text + image)\n",
    "    combine_repr = tf.keras.layers.concatenate([text_repr, visual_repr])\n",
    "    com_drop = tf.keras.layers.Dropout(params['dropout'])(combine_repr)\n",
    "\n",
    "    if params['final_no_hidden_layer'] > 0:\n",
    "        for i in range(params['final_no_hidden_layer']):\n",
    "            com_drop = tf.keras.layers.Dense(params['final_hidden_neurons'], activation='relu')(com_drop)\n",
    "            com_drop = tf.keras.layers.Dropout(params['dropout'])(com_drop)\n",
    "\n",
    "    prediction = tf.keras.layers.Dense(1, activation='sigmoid')(com_drop)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[in_id, in_mask, in_segment, input_image], outputs=prediction)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=params['optimizer'](), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"✓ Model definition ready (TPU-compatible)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5379f",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def get_df(file):\n",
    "    return pd.read_csv(file, sep='\\t')\n",
    "\n",
    "train_df = get_df(f'{DATASET_PATH}/train_posts.txt')\n",
    "test_df = get_df(f'{DATASET_PATH}/test_posts.txt')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first image ID\n",
    "def return_first_image(row):\n",
    "    return row['image_id'].split(',')[0].strip()\n",
    "\n",
    "train_df['first_image_id'] = train_df.progress_apply(lambda row: return_first_image(row), axis=1)\n",
    "test_df['first_image_id'] = test_df.progress_apply(lambda row: return_first_image(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out missing images\n",
    "images_train_dataset = [i for i in train_df['first_image_id'].tolist()]\n",
    "images_train_folder = [i.split('.')[0].strip() for i in listdir(f'{DATASET_PATH}/images_train')]\n",
    "images_train_not_available = set(images_train_dataset) - set(images_train_folder)\n",
    "images_train_not_available.add('boston_fake_10')\n",
    "\n",
    "images_test_dataset = [i.split(',')[0].strip() for i in test_df['image_id'].tolist()]\n",
    "images_test_folder = [i.split('.')[0].strip() for i in listdir(f'{DATASET_PATH}/images_test/')]\n",
    "images_test_not_available = set(images_test_dataset) - set(images_test_folder)\n",
    "\n",
    "train_df = train_df[~train_df['first_image_id'].isin(images_train_not_available)]\n",
    "test_df = test_df[~test_df['first_image_id'].isin(images_test_not_available)]\n",
    "\n",
    "print(f\"After filtering - Train: {train_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and labels\n",
    "train_text = train_df['post_text'].tolist()\n",
    "test_text = test_df['post_text'].tolist()\n",
    "\n",
    "train_images = [i for i in train_df['first_image_id'].tolist()]\n",
    "test_images = [i for i in test_df['first_image_id'].tolist()]\n",
    "\n",
    "trainY = train_df['label'].tolist()\n",
    "trainY = [1 if i == 'real' else 0 for i in trainY]\n",
    "\n",
    "testY = test_df['label'].tolist()\n",
    "testY = [1 if i == 'real' else 0 for i in testY]\n",
    "\n",
    "print(f\"Data counts: {len(train_text)} train, {len(test_text)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe04996",
   "metadata": {},
   "source": [
    "### Process Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, trainY)\n",
    "test_examples = convert_text_to_examples(test_text, testY)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, trainY_processed\n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "(test_input_ids, test_input_masks, test_segment_ids, testY_processed\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "print(f\"Text features shape: {train_input_ids.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b22ed",
   "metadata": {},
   "source": [
    "### Process Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd87fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image file extensions\n",
    "images = listdir(f'{DATASET_PATH}/images_train/')\n",
    "images.extend(listdir(f'{DATASET_PATH}/images_test/'))\n",
    "jpg, png, jpeg, gif = [], [], [], []\n",
    "\n",
    "valid_extensions = {'jpg', 'png', 'jpeg', 'gif'}\n",
    "for i in images:\n",
    "    if '.' not in i or i.startswith('.'):\n",
    "        continue\n",
    "    name, ext = i.split('.')[0], i.split('.')[-1].lower()\n",
    "    if ext in valid_extensions:\n",
    "        if ext == 'jpg':\n",
    "            jpg.append(name)\n",
    "        elif ext == 'png':\n",
    "            png.append(name)\n",
    "        elif ext == 'jpeg':\n",
    "            jpeg.append(name)\n",
    "        elif ext == 'gif':\n",
    "            gif.append(name)\n",
    "\n",
    "def get_extension_of_file(file_name):\n",
    "    if file_name in jpg:\n",
    "        return '.jpg'\n",
    "    elif file_name in png:\n",
    "        return '.png'\n",
    "    elif file_name in jpeg:\n",
    "        return '.jpeg'\n",
    "    else:\n",
    "        return '.gif'\n",
    "\n",
    "print(f\"Found: {len(jpg)} jpg, {len(png)} png, {len(jpeg)} jpeg, {len(gif)} gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build full image paths\n",
    "train_image_paths = [f'{DATASET_PATH}/images_train/' + i + get_extension_of_file(i) for i in train_images]\n",
    "test_image_paths = [f'{DATASET_PATH}/images_test/' + i + get_extension_of_file(i) for i in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc388119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images\n",
    "print(\"Processing images (this may take a while)...\")\n",
    "train_imagesX = read_and_process_image(train_image_paths)\n",
    "test_imagesX = read_and_process_image(test_image_paths)\n",
    "\n",
    "# Convert to (batch, channels, height, width) format\n",
    "train_imagesX = np.rollaxis(train_imagesX, 3, 1)\n",
    "test_imagesX = np.rollaxis(test_imagesX, 3, 1)\n",
    "\n",
    "print(f\"Image data shape: {train_imagesX.shape}\")\n",
    "print(\"✓ Image preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e5fd9",
   "metadata": {},
   "source": [
    "## 5. Model Training with TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94901c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters (from hyperparameter search)\n",
    "params_final = {\n",
    "    'text_no_hidden_layer': 1,\n",
    "    'text_hidden_neurons': 768,\n",
    "    'dropout': 0.4,\n",
    "    'repr_size': 32,\n",
    "    'vis_no_hidden_layer': 1,\n",
    "    'vis_hidden_neurons': 2742,\n",
    "    'final_no_hidden_layer': 1,\n",
    "    'final_hidden_neurons': 35,\n",
    "    'optimizer': tf.keras.optimizers.Adam\n",
    "}\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "for k, v in params_final.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model within TPU strategy scope\n",
    "with strategy.scope():\n",
    "    model = get_news_model(params_final)\n",
    "    model.optimizer.learning_rate.assign(0.0005)\n",
    "    print(f\"Learning rate set to: {model.optimizer.learning_rate.numpy()}\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup checkpoint callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'model-{epoch:03d}-{val_accuracy:.6f}.h5', \n",
    "    verbose=1, \n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True, \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"✓ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust batch size for TPU (TPUs work best with larger batch sizes)\n",
    "# TPU v5e-8 has 8 cores, so batch size should be divisible by 8\n",
    "if using_tpu:\n",
    "    batch_size = 256  # 32 per core * 8 cores\n",
    "    epochs = 10\n",
    "else:\n",
    "    batch_size = 128\n",
    "    epochs = 10\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Using: {'TPU' if using_tpu else 'GPU/CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids, train_imagesX], \n",
    "    trainY_processed,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    validation_data=(\n",
    "        [test_input_ids, test_input_masks, test_segment_ids, test_imagesX],\n",
    "        testY_processed\n",
    "    ),\n",
    "    callbacks=[live(), checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301d3a3",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e13181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate current model\n",
    "test_predictions = model.predict([\n",
    "    test_input_ids, test_input_masks, test_segment_ids, test_imagesX\n",
    "])\n",
    "test_predictions_binary = [1 if i >= 0.5 else 0 for i in test_predictions]\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(f\"Accuracy:  {accuracy_score(testY_processed, test_predictions_binary):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(testY_processed, test_predictions_binary, average=None)}\")\n",
    "print(f\"Precision: {precision_score(testY_processed, test_predictions_binary, average=None)}\")\n",
    "print(f\"Recall:    {recall_score(testY_processed, test_predictions_binary, average=None)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5977185",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "model.save('spotfake_tpu_model.h5')\n",
    "print(\"✓ Model saved to 'spotfake_tpu_model.h5'\")\n",
    "\n",
    "# To load the model later:\n",
    "# loaded_model = tf.keras.models.load_model('spotfake_tpu_model.h5', custom_objects={'KerasLayer': hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c07c6e",
   "metadata": {},
   "source": [
    "## 8. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4406425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fake_news(text, image_path, model, tokenizer, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict whether a news post (text + image) is fake or real.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The post text\n",
    "        image_path (str): Path to the image file\n",
    "        model: Trained Keras model\n",
    "        tokenizer: BERT tokenizer\n",
    "        threshold (float): Classification threshold (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    # Preprocess text\n",
    "    input_ids, input_masks, segment_ids = preprocess_text_input(\n",
    "        text, tokenizer, max_seq_length=max_seq_length\n",
    "    )\n",
    "    \n",
    "    # Preprocess image\n",
    "    image_data = preprocess_single_image(image_path, length=img_length, width=img_width)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(\n",
    "        [input_ids, input_masks, segment_ids, image_data],\n",
    "        verbose=0\n",
    "    )[0][0]\n",
    "    \n",
    "    # Classify\n",
    "    is_real = prediction >= threshold\n",
    "    label = \"REAL\" if is_real else \"FAKE\"\n",
    "    confidence = prediction if is_real else (1 - prediction)\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'confidence': float(confidence),\n",
    "        'raw_score': float(prediction),\n",
    "        'text': text,\n",
    "        'image_path': image_path\n",
    "    }\n",
    "\n",
    "print(\"✓ Inference function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "sample_text = \"Breaking news: Major event happening now!\"\n",
    "sample_image_path = test_image_paths[0]\n",
    "\n",
    "result = predict_fake_news(sample_text, sample_image_path, model, tokenizer)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREDICTION RESULT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Text: {result['text']}\")\n",
    "print(f\"Image: {result['image_path']}\")\n",
    "print(f\"\\nPrediction: {result['label']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"Raw Score: {result['raw_score']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display the image\n",
    "img = cv2.imread(sample_image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(f\"Prediction: {result['label']} ({result['confidence']:.2%} confidence)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef7f37",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has been optimized for Kaggle TPU v5e-8:\n",
    "\n",
    "### Key TPU Optimizations:\n",
    "1. **TPU Detection & Strategy**: Automatic TPU detection and distribution strategy\n",
    "2. **Batch Size**: Increased to 256 (optimal for 8 TPU cores)\n",
    "3. **Model Scope**: Model created within `strategy.scope()`\n",
    "4. **Data Paths**: Configured for Kaggle's `/kaggle/input/` structure\n",
    "\n",
    "### To Use This Notebook:\n",
    "1. Upload your SpotFake dataset to Kaggle Datasets\n",
    "2. Update `DATASET_PATH` variable with your dataset name\n",
    "3. In Notebook Settings: Select **TPU v5e-8** as accelerator\n",
    "4. Run all cells in order\n",
    "\n",
    "### Expected Performance:\n",
    "- Training speed: ~3-5x faster than GPU on large batches\n",
    "- Best for: Large datasets with batch sizes ≥256\n",
    "- Model accuracy: Similar to GPU/CPU training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
