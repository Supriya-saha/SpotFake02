{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921b3c2b",
   "metadata": {},
   "source": [
    "# SpotFake: Complete Model with Cross-Modal Attention & Contrastive Learning\n",
    "\n",
    "**Clean implementation for training and testing**\n",
    "\n",
    "- ✅ ResNet50 + BERT multimodal fusion\n",
    "- ✅ Cross-modal attention (text ↔ image)\n",
    "- ✅ Supervised contrastive learning\n",
    "- ✅ Multi-GPU training support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6697e0",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Supriya-saha/SpotFake02.git\n",
    "!rm -rf sample_data\n",
    "# Move all files from SpotFake02 to current directory (/content)\n",
    "!mv SpotFake02/* .\n",
    "\n",
    "# Include hidden files (like .env, .gitignore)\n",
    "!shopt -s dotglob && mv SpotFake02/* . && shopt -u dotglob\n",
    "\n",
    "# Remove the empty folder\n",
    "!rmdir SpotFake02\n",
    "!pip install -r requirements.txt\n",
    "!pip install -q --upgrade transformers huggingface_hub\n",
    "!curl -L -o vocab.txt https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPUs available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Multi-GPU strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d54df",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85266e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_CSV = 'dataset/twitter/train_posts.csv'\n",
    "TEST_CSV = 'dataset/twitter/test_posts.csv'\n",
    "TRAIN_IMG_DIR = 'dataset/twitter/images_train'\n",
    "TEST_IMG_DIR = 'dataset/twitter/images_test'\n",
    "CHECKPOINT_DIR = 'checkpoints_final'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Model parameters\n",
    "CONFIG = {\n",
    "    'max_length': 23,\n",
    "    'image_size': 224,\n",
    "    'bert_model': 'bert-base-uncased',\n",
    "    'bert_dim': 768,\n",
    "    'resnet_dim': 2048,\n",
    "    'attention_heads': 4,\n",
    "    'attention_dim': 256,\n",
    "    'projection_dim': 128,\n",
    "    'temperature': 0.07,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 1e-4\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c687ae0",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Auto-detect column names\n",
    "text_col = next((c for c in ['tweet', 'post_text', 'text', 'content'] if c in df_train.columns), 'text')\n",
    "label_col = next((c for c in ['label', '2_way_label', 'class'] if c in df_train.columns), 'label')\n",
    "\n",
    "# Convert string labels to numeric\n",
    "if df_train[label_col].dtype == 'object':\n",
    "    label_map = {'fake': 1, 'Fake': 1, 'FAKE': 1, 'real': 0, 'Real': 0, 'REAL': 0}\n",
    "    df_train[label_col] = df_train[label_col].map(label_map)\n",
    "    df_test[label_col] = df_test[label_col].map(label_map)\n",
    "\n",
    "# Rename for consistency\n",
    "df_train = df_train.rename(columns={text_col: 'text', label_col: 'label'})\n",
    "df_test = df_test.rename(columns={text_col: 'text', label_col: 'label'})\n",
    "\n",
    "print(f\"Train: {len(df_train)} posts\")\n",
    "print(f\"Test:  {len(df_test)} posts\")\n",
    "print(f\"Fake ratio: {df_train['label'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca45dc",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(CONFIG['bert_model'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=CONFIG['max_length'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    return encoding['input_ids'], encoding['attention_mask'], encoding['token_type_ids']\n",
    "\n",
    "def load_image(image_path):\n",
    "    # Try different extensions\n",
    "    if not os.path.exists(image_path):\n",
    "        for ext in ['.jpg', '.jpeg', '.png']:\n",
    "            if os.path.exists(image_path + ext):\n",
    "                image_path = image_path + ext\n",
    "                break\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [CONFIG['image_size'], CONFIG['image_size']])\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "    return tf.zeros([CONFIG['image_size'], CONFIG['image_size'], 3])\n",
    "\n",
    "def data_generator(df, image_dir):\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        image_path = os.path.join(image_dir, str(row['image_id']))\n",
    "        label = float(row['label'])\n",
    "        \n",
    "        input_ids, masks, segments = preprocess_text(text)\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        yield (np.array(input_ids), np.array(masks), np.array(segments), image.numpy()), label\n",
    "\n",
    "def create_dataset(df, image_dir, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: data_generator(df, image_dir),\n",
    "        output_signature=(\n",
    "            (\n",
    "                tf.TensorSpec(shape=(CONFIG['max_length'],), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(CONFIG['max_length'],), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(CONFIG['max_length'],), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(CONFIG['image_size'], CONFIG['image_size'], 3), dtype=tf.float32)\n",
    "            ),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "print(\"Data pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0163a7c",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f16b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEncoder(layers.Layer):\n",
    "    \"\"\"Custom BERT encoder layer wrapper\"\"\"\n",
    "    \n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.config = config\n",
    "        self.bert = None\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        from transformers import TFBertModel\n",
    "        # Load BERT - try different methods\n",
    "        try:\n",
    "            self.bert = TFBertModel.from_pretrained(self.config['bert_model'], from_pt=True)\n",
    "        except:\n",
    "            try:\n",
    "                self.bert = TFBertModel.from_pretrained(self.config['bert_model'], use_safetensors=False)\n",
    "            except:\n",
    "                self.bert = TFBertModel.from_pretrained(self.config['bert_model'])\n",
    "        \n",
    "        self.bert.trainable = False\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask, token_type_ids = inputs\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            training=False\n",
    "        )\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "def create_bert_encoder(config):\n",
    "    \"\"\"BERT text encoder using custom layer\"\"\"\n",
    "    input_ids = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='input_ids')\n",
    "    masks = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='attention_mask')\n",
    "    segments = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='token_type_ids')\n",
    "    \n",
    "    bert_layer = BERTEncoder(config, name='bert_encoder')\n",
    "    sequence_output = bert_layer([input_ids, masks, segments])\n",
    "    \n",
    "    return keras.Model(\n",
    "        inputs=[input_ids, masks, segments],\n",
    "        outputs=sequence_output,\n",
    "        name='bert_encoder'\n",
    "    )\n",
    "\n",
    "def create_resnet_encoder(config):\n",
    "    \"\"\"ResNet50 image encoder\"\"\"\n",
    "    input_image = layers.Input(shape=(config['image_size'], config['image_size'], 3), name='image')\n",
    "    \n",
    "    resnet = keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling=None\n",
    "    )\n",
    "    resnet.trainable = False\n",
    "    \n",
    "    features = resnet(input_image)\n",
    "    \n",
    "    return keras.Model(\n",
    "        inputs=input_image,\n",
    "        outputs=features,\n",
    "        name='resnet_encoder'\n",
    "    )\n",
    "\n",
    "def cross_attention_block(query, key_value, num_heads, dim, name_prefix):\n",
    "    \"\"\"Cross-modal attention layer\"\"\"\n",
    "    attention = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=dim // num_heads,\n",
    "        name=f\"{name_prefix}_attention\"\n",
    "    )\n",
    "    \n",
    "    attended = attention(query=query, key=key_value, value=key_value)\n",
    "    attended = layers.Add()([query, attended])\n",
    "    attended = layers.LayerNormalization()(attended)\n",
    "    \n",
    "    return attended\n",
    "\n",
    "def create_complete_model(config):\n",
    "    \"\"\"Complete model with cross-attention and contrastive learning\"\"\"\n",
    "    \n",
    "    # Inputs\n",
    "    input_ids = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='input_ids')\n",
    "    masks = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='attention_mask')\n",
    "    segments = layers.Input(shape=(config['max_length'],), dtype=tf.int32, name='token_type_ids')\n",
    "    images = layers.Input(shape=(config['image_size'], config['image_size'], 3), name='image')\n",
    "    \n",
    "    # Encoders\n",
    "    bert_encoder = create_bert_encoder(config)\n",
    "    resnet_encoder = create_resnet_encoder(config)\n",
    "    \n",
    "    # Extract features\n",
    "    text_features = bert_encoder([input_ids, masks, segments])\n",
    "    image_features = resnet_encoder(images)\n",
    "    \n",
    "    # Reshape image features\n",
    "    batch_size = tf.shape(image_features)[0]\n",
    "    image_h = tf.shape(image_features)[1]\n",
    "    image_w = tf.shape(image_features)[2]\n",
    "    image_seq = tf.reshape(image_features, [batch_size, image_h * image_w, config['resnet_dim']])\n",
    "    \n",
    "    # Project to same dimension\n",
    "    text_proj = layers.Dense(config['attention_dim'], name='text_projection')(text_features)\n",
    "    image_proj = layers.Dense(config['attention_dim'], name='image_projection')(image_seq)\n",
    "    \n",
    "    # Cross-modal attention\n",
    "    text_attended = cross_attention_block(\n",
    "        text_proj, image_proj, \n",
    "        config['attention_heads'], config['attention_dim'], \n",
    "        'text_to_image'\n",
    "    )\n",
    "    image_attended = cross_attention_block(\n",
    "        image_proj, text_proj,\n",
    "        config['attention_heads'], config['attention_dim'],\n",
    "        'image_to_text'\n",
    "    )\n",
    "    \n",
    "    # Global pooling\n",
    "    text_pooled = layers.GlobalAveragePooling1D()(text_attended)\n",
    "    image_pooled = layers.GlobalAveragePooling1D()(image_attended)\n",
    "    \n",
    "    # Concatenate\n",
    "    combined = layers.Concatenate()([text_pooled, image_pooled])\n",
    "    combined = layers.Dropout(config['dropout'])(combined)\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(256, activation='relu')(combined)\n",
    "    x = layers.Dropout(config['dropout'])(x)\n",
    "    classification_output = layers.Dense(1, activation='sigmoid', name='classification')(x)\n",
    "    \n",
    "    # Projection heads for contrastive learning\n",
    "    text_contrastive = layers.Dense(config['projection_dim'], name='text_contrastive')(text_pooled)\n",
    "    text_contrastive = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(text_contrastive)\n",
    "    \n",
    "    image_contrastive = layers.Dense(config['projection_dim'], name='image_contrastive')(image_pooled)\n",
    "    image_contrastive = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(image_contrastive)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=[input_ids, masks, segments, images],\n",
    "        outputs={\n",
    "            'classification': classification_output,\n",
    "            'text_projection': text_contrastive,\n",
    "            'image_projection': image_contrastive\n",
    "        },\n",
    "        name='spotfake_complete'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44086dc",
   "metadata": {},
   "source": [
    "## 6. Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc15a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    \"\"\"Supervised contrastive loss (InfoNCE)\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=0.07, name='contrastive_loss'):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def call(self, labels, projections):\n",
    "        text_proj, image_proj = projections\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        embeddings = tf.concat([text_proj, image_proj], axis=0)\n",
    "        labels_concat = tf.concat([labels, labels], axis=0)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity = tf.matmul(embeddings, embeddings, transpose_b=True) / self.temperature\n",
    "        \n",
    "        # Mask for positive pairs (same label)\n",
    "        labels_eq = tf.cast(tf.equal(tf.expand_dims(labels_concat, 0), \n",
    "                                     tf.expand_dims(labels_concat, 1)), tf.float32)\n",
    "        \n",
    "        # Mask out diagonal\n",
    "        batch_size = tf.shape(embeddings)[0]\n",
    "        mask_diag = 1.0 - tf.eye(batch_size)\n",
    "        labels_eq = labels_eq * mask_diag\n",
    "        \n",
    "        # Compute loss\n",
    "        exp_sim = tf.exp(similarity) * mask_diag\n",
    "        log_prob = similarity - tf.math.log(tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9)\n",
    "        \n",
    "        mean_log_prob = tf.reduce_sum(labels_eq * log_prob, axis=1) / (tf.reduce_sum(labels_eq, axis=1) + 1e-9)\n",
    "        loss = -tf.reduce_mean(mean_log_prob)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "print(\"Contrastive loss defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8ba94",
   "metadata": {},
   "source": [
    "## 7. Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af606bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotFakeModel(keras.Model):\n",
    "    \"\"\"Custom model with multi-task training\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model, classification_weight=1.0, contrastive_weight=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.base_model = base_model\n",
    "        self.classification_weight = classification_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        \n",
    "        self.classification_loss_fn = keras.losses.BinaryCrossentropy()\n",
    "        self.contrastive_loss_fn = SupervisedContrastiveLoss(temperature=CONFIG['temperature'])\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name='loss')\n",
    "        self.cls_loss_tracker = keras.metrics.Mean(name='classification_loss')\n",
    "        self.con_loss_tracker = keras.metrics.Mean(name='contrastive_loss')\n",
    "        self.accuracy_tracker = keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        return self.base_model(inputs, training=training)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.base_model(x, training=True)\n",
    "            \n",
    "            cls_loss = self.classification_loss_fn(y, outputs['classification'])\n",
    "            con_loss = self.contrastive_loss_fn(\n",
    "                tf.reshape(y, [-1]),\n",
    "                (outputs['text_projection'], outputs['image_projection'])\n",
    "            )\n",
    "            \n",
    "            total_loss = self.classification_weight * cls_loss + self.contrastive_weight * con_loss\n",
    "        \n",
    "        gradients = tape.gradient(total_loss, self.base_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.base_model.trainable_variables))\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.cls_loss_tracker.update_state(cls_loss)\n",
    "        self.con_loss_tracker.update_state(con_loss)\n",
    "        self.accuracy_tracker.update_state(y, outputs['classification'])\n",
    "        \n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'classification_loss': self.cls_loss_tracker.result(),\n",
    "            'contrastive_loss': self.con_loss_tracker.result(),\n",
    "            'accuracy': self.accuracy_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        \n",
    "        outputs = self.base_model(x, training=False)\n",
    "        \n",
    "        cls_loss = self.classification_loss_fn(y, outputs['classification'])\n",
    "        con_loss = self.contrastive_loss_fn(\n",
    "            tf.reshape(y, [-1]),\n",
    "            (outputs['text_projection'], outputs['image_projection'])\n",
    "        )\n",
    "        total_loss = self.classification_weight * cls_loss + self.contrastive_weight * con_loss\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.cls_loss_tracker.update_state(cls_loss)\n",
    "        self.con_loss_tracker.update_state(con_loss)\n",
    "        self.accuracy_tracker.update_state(y, outputs['classification'])\n",
    "        \n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'classification_loss': self.cls_loss_tracker.result(),\n",
    "            'contrastive_loss': self.con_loss_tracker.result(),\n",
    "            'accuracy': self.accuracy_tracker.result()\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.cls_loss_tracker,\n",
    "            self.con_loss_tracker,\n",
    "            self.accuracy_tracker\n",
    "        ]\n",
    "\n",
    "print(\"Custom training model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b71a84",
   "metadata": {},
   "source": [
    "## 8. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model = create_complete_model(CONFIG)\n",
    "    model = SpotFakeModel(\n",
    "        base_model,\n",
    "        classification_weight=1.0,\n",
    "        contrastive_weight=0.5\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n",
    "    )\n",
    "\n",
    "print(f\"\\n✓ Model built with {strategy.num_replicas_in_sync} GPU(s)\")\n",
    "print(f\"Total parameters: {base_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9fe57",
   "metadata": {},
   "source": [
    "## 9. Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "train_size = int(0.9 * len(df_train))\n",
    "df_train_split = df_train[:train_size]\n",
    "df_val_split = df_train[train_size:]\n",
    "\n",
    "print(f\"Train: {len(df_train_split)} posts\")\n",
    "print(f\"Val:   {len(df_val_split)} posts\")\n",
    "print(f\"Test:  {len(df_test)} posts\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_dataset(df_train_split, TRAIN_IMG_DIR, CONFIG['batch_size'], shuffle=True)\n",
    "val_dataset = create_dataset(df_val_split, TRAIN_IMG_DIR, CONFIG['batch_size'], shuffle=False)\n",
    "test_dataset = create_dataset(df_test, TEST_IMG_DIR, 16, shuffle=False)\n",
    "\n",
    "print(\"\\n✓ Datasets created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405a1eb",
   "metadata": {},
   "source": [
    "## 10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_DIR, 'best_model.weights.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=False,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7da7a",
   "metadata": {},
   "source": [
    "## 11. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cad482",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Accuracy')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Total Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Train')\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Total Loss')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Classification Loss\n",
    "axes[1, 0].plot(history.history['classification_loss'], label='Train')\n",
    "axes[1, 0].plot(history.history['val_classification_loss'], label='Validation')\n",
    "axes[1, 0].set_title('Classification Loss')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Contrastive Loss\n",
    "axes[1, 1].plot(history.history['contrastive_loss'], label='Train')\n",
    "axes[1, 1].plot(history.history['val_contrastive_loss'], label='Validation')\n",
    "axes[1, 1].set_title('Contrastive Loss')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323ff8a",
   "metadata": {},
   "source": [
    "## 12. Testing & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45106fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\\n\")\n",
    "\n",
    "# Evaluate\n",
    "test_results = model.evaluate(test_dataset, verbose=1)\n",
    "\n",
    "# Get predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for batch_inputs, batch_labels in tqdm(test_dataset, desc=\"Predicting\"):\n",
    "    outputs = base_model(batch_inputs, training=False)\n",
    "    predictions = outputs['classification'].numpy().flatten()\n",
    "    all_predictions.extend(predictions)\n",
    "    all_labels.extend(batch_labels.numpy().flatten())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "binary_preds = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "precision = precision_score(all_labels, binary_preds)\n",
    "recall = recall_score(all_labels, binary_preds)\n",
    "f1 = f1_score(all_labels, binary_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, binary_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              Genuine  Fake\")\n",
    "print(f\"Actual Genuine  {conf_matrix[0][0]:>6}  {conf_matrix[0][1]:>5}\")\n",
    "print(f\"       Fake     {conf_matrix[1][0]:>6}  {conf_matrix[1][1]:>5}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, binary_preds, target_names=['Genuine', 'Fake']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbf424",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "results_df = df_test.copy()\n",
    "results_df['predicted_label'] = binary_preds\n",
    "results_df['probability_fake'] = all_predictions\n",
    "results_df['confidence'] = np.where(all_predictions > 0.5, all_predictions, 1 - all_predictions)\n",
    "\n",
    "results_df.to_csv('test_predictions.csv', index=False)\n",
    "print(\"✓ Predictions saved to: test_predictions.csv\")\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'confusion_matrix': conf_matrix.tolist(),\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('results_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"✓ Summary saved to: results_summary.json\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING AND EVALUATION COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
